{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# \n",
    "path = \"/kaggle/input/ifood-data/\" \n",
    "batch_size = 16\n",
    "train_path = path + \"train_set/train_set\"\n",
    "train_labels = path + \"train_info.csv\"\n",
    "val_path = path + \"val_set/val_set\"\n",
    "val_labels = path + \"val_info.csv\"\n",
    "test_path = path + \"test_set\"\n",
    "\n",
    "USE_GPU = True \n",
    "print_every = 11800\n",
    "\n",
    "# hyperparameters used for training \n",
    "batch_size = 16\n",
    "momentum = 0.9 \n",
    "lr = 0.0005\n",
    "epochs = 6\n",
    "\n",
    "# initialize model weights and optimization algorithm \n",
    "model = models.resnet152(pretrained=True)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=lr, momentum=momentum, nesterov=True)\n",
    "\n",
    "save_path = \"/kaggle/working/resnet152_10epochs.pth\"\n",
    "submission_name = \"submission.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. \n",
    "    Extendstorchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"Custom dataset object for loading images and image labels\n",
    "    Extends torch.utils.data.Dataset\n",
    "    -----------\n",
    "    image_path: location of the folder where the images are stored \n",
    "    image_names: list of all of the image files at the location \n",
    "    label_path: the path to the csv of the corresponding label to each image\n",
    "    \"\"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "    def __init__(self, \n",
    "                 image_path, \n",
    "                 image_names, \n",
    "                 label_path,  transform=None):\n",
    "\n",
    "        self.image_path = image_path \n",
    "        self.image_names = image_names \n",
    "        self.transform = transform\n",
    "        # reads a csv of all the labels \n",
    "        self.labels = pd.read_csv(label_path, \n",
    "                                  names=[\"img_name\", \"label\"])\n",
    "        \n",
    "    def get_class_label(self, image_name):\n",
    "        y = self.labels[self.labels[\"img_name\"] == image_name].iloc[0][\"label\"]\n",
    "        return y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        path = self.image_path + \"/\" + self.image_names[index]\n",
    "        # get the image and the label \n",
    "        x = Image.open(path)\n",
    "        y = self.get_class_label(path.split('/')[-1])\n",
    "        # apply transformations \n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_names = [] \n",
    "# get the list of all images in the validation set  \n",
    "for dirname, _, filenames in os.walk(val_path):\n",
    "    for filename in filenames:\n",
    "        val_names.append(filename)\n",
    "        count += 1\n",
    "\n",
    "train_names = [] \n",
    "# get the list of all images in the training set \n",
    "for dirname, _, filenames in os.walk(train_path):\n",
    "    for filename in filenames:\n",
    "        train_names.append(filename)\n",
    "        count += 1\n",
    "\n",
    "# the following will apply a list of transformations to the images\n",
    "# transformations for the training set \n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.768986940,.6641706 ,0.5923363),\n",
    "                         (0.18613161, 0.22524446, 0.23932885))])\n",
    "\n",
    "# transformations for the validation set \n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.768986940,.6641706 ,0.5923363),\n",
    "                         (0.18613161, 0.22524446, 0.23932885))])\n",
    "\n",
    "# transformations for the test set \n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.768986940,.6641706 ,0.5923363),\n",
    "                         (0.18613161, 0.22524446, 0.23932885))])    \n",
    "\n",
    "# create training and validation datasets \n",
    "train_data = MyDataset(train_path, \n",
    "                       train_names, \n",
    "                       train_labels, \n",
    "                       transform= train_transforms)  \n",
    "val_data = MyDataset(val_path, \n",
    "                     val_names, \n",
    "                     val_labels, \n",
    "                     transform= val_transforms)\n",
    "\n",
    "# load testing images from path \n",
    "test_data = ImageFolderWithPaths(test_path, \n",
    "                                 transform = test_transforms)\n",
    "\n",
    "\n",
    "# create data loader objects for batch gradient descent \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# load an image one at a time for test set \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a GPU is available \n",
    "dtype = torch.float32 \n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \"\"\"calculates model accuracy on data loader \n",
    "    ----------\n",
    "    loader: the dataset to check on, e.g train_loader, val_loader, test_loader\n",
    "    model: a pytorch deeplearning model\n",
    "    ----------\n",
    "    output: prints the accuracy \n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            # idenitfy the group with the highest value \n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        \n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def train(model, optimizer, epochs):\n",
    "    \"\"\"performs gradient descent with optimizer \n",
    "    ------------\n",
    "    model: a pytorch model \n",
    "    optimizer: optimizer from pytorch.optim \n",
    "    epochs: the number of epochs to train for \n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                print(t, loss.item())\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(val_loader, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(val_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device=device)\n",
    "\n",
    "# load testing images and write predicted labels into a txt file \n",
    "with open(submission_name, 'w') as file:\n",
    "    file.write(\"img_name,label\\n\")\n",
    "    with torch.no_grad():\n",
    "        for x, y, path in test_loader:\n",
    "            name = path[0][-15:]\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            scores = model(x)\n",
    "            out_labels = [int(x) for x in (torch.topk(scores, 3)[1][0])]\n",
    "            file.write(name + \",\" + str(out_labels[0]) + \" \" + str(out_labels[1]) + \" \" + str(out_labels[2]) + \"\\n\")\n",
    "print(\"done writing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
