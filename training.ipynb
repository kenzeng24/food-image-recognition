{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 0\n",
    "NUM_VAL = 0\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.768986940,.6641706 ,0.5923363),(0.18613161, 0.22524446, 0.23932885))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.768986940,.6641706 ,0.5923363),(0.18613161, 0.22524446, 0.23932885))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.768986940,.6641706 ,0.5923363),(0.18613161, 0.22524446, 0.23932885))\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"train\", transform=train_transforms)\n",
    "val_data = datasets.ImageFolder(\"val\", transform = val_transforms)\n",
    "test_data = ImageFolderWithPaths(\"test\", transform = test_transforms)\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True\n",
    "                                        )\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 11800\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):  \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def train(model, optimizer, epochs):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                print(t, loss.item())\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(val_loader, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.629727840423584\n",
      "Iteration 0, loss = 5.6297\n",
      "Got 51 / 11994 correct (0.43)\n",
      "\n",
      "100 5.6182122230529785\n",
      "200 5.466123104095459\n",
      "300 4.838940143585205\n",
      "400 4.867872714996338\n",
      "500 5.372663497924805\n",
      "600 4.668335914611816\n",
      "700 4.513436794281006\n",
      "800 4.877199172973633\n",
      "900 4.866020679473877\n",
      "1000 4.656344890594482\n",
      "1100 3.896261215209961\n",
      "1200 3.7679102420806885\n",
      "1300 4.67205810546875\n",
      "1400 3.9424381256103516\n",
      "1500 4.714105129241943\n",
      "1600 4.459527969360352\n",
      "1700 3.8977839946746826\n",
      "1800 4.569260597229004\n",
      "1900 4.1941633224487305\n",
      "2000 4.760339736938477\n",
      "2100 3.9242098331451416\n",
      "2200 3.87227463722229\n",
      "2300 3.698213815689087\n",
      "2400 4.435128688812256\n",
      "2500 3.567122220993042\n",
      "2600 4.389989376068115\n",
      "2700 4.440151214599609\n",
      "2800 4.191368579864502\n",
      "2900 3.3194189071655273\n",
      "3000 3.649888753890991\n",
      "3100 3.4508800506591797\n",
      "3200 3.9935734272003174\n",
      "3300 4.125541687011719\n",
      "3400 3.128769636154175\n",
      "3500 3.641315460205078\n",
      "3600 4.828465938568115\n",
      "3700 3.4607436656951904\n",
      "3800 3.5418968200683594\n",
      "3900 3.639989137649536\n",
      "4000 3.5609219074249268\n",
      "4100 3.326289415359497\n",
      "4200 4.115733623504639\n",
      "4300 3.3646011352539062\n",
      "4400 4.0745978355407715\n",
      "4500 3.2065060138702393\n",
      "4600 3.96162486076355\n",
      "4700 4.62768030166626\n",
      "4800 3.4108259677886963\n",
      "4900 3.4980719089508057\n",
      "5000 4.353909015655518\n",
      "5100 3.4719784259796143\n",
      "5200 3.825080156326294\n",
      "5300 3.3677074909210205\n",
      "5400 4.321789264678955\n",
      "5500 3.123107671737671\n",
      "5600 3.0357372760772705\n",
      "5700 3.2466557025909424\n",
      "5800 3.859912157058716\n",
      "5900 4.129272937774658\n",
      "6000 4.177130222320557\n",
      "6100 3.7355544567108154\n",
      "6200 3.9200592041015625\n",
      "6300 4.193393707275391\n",
      "6400 3.952432870864868\n",
      "6500 3.951120138168335\n",
      "6600 2.925947904586792\n",
      "6700 3.58599853515625\n",
      "6800 4.011022567749023\n",
      "6900 3.0774593353271484\n",
      "7000 5.139558792114258\n",
      "7100 3.5612986087799072\n",
      "7200 2.7727773189544678\n",
      "7300 3.563295364379883\n",
      "7400 2.6551191806793213\n",
      "7500 4.003615856170654\n",
      "7600 3.6858294010162354\n",
      "7700 3.7409026622772217\n",
      "7800 4.799263000488281\n",
      "7900 2.969432830810547\n",
      "8000 3.6451776027679443\n",
      "8100 3.7072808742523193\n",
      "8200 4.532106876373291\n",
      "8300 3.8206634521484375\n",
      "8400 3.355492353439331\n",
      "8500 3.4220240116119385\n",
      "8600 3.4602038860321045\n",
      "8700 3.265493392944336\n",
      "8800 4.180400371551514\n",
      "8900 3.215738534927368\n",
      "9000 3.747720718383789\n",
      "9100 2.2617104053497314\n",
      "9200 3.022662401199341\n",
      "9300 3.755828857421875\n",
      "9400 3.9332733154296875\n",
      "9500 3.7255287170410156\n",
      "9600 2.274973154067993\n",
      "9700 2.7811548709869385\n",
      "9800 3.982403039932251\n",
      "0 3.2313506603240967\n",
      "Iteration 0, loss = 3.2314\n",
      "Got 3550 / 11994 correct (29.60)\n",
      "\n",
      "100 4.243408679962158\n",
      "200 2.234971761703491\n",
      "300 3.833221435546875\n",
      "400 2.509617805480957\n",
      "500 3.148409843444824\n",
      "600 2.97660756111145\n",
      "700 3.136996269226074\n",
      "800 3.7525317668914795\n",
      "900 2.7665350437164307\n",
      "1000 3.340925931930542\n",
      "1100 3.0897560119628906\n",
      "1200 3.225677251815796\n",
      "1300 2.6797311305999756\n",
      "1400 2.8204848766326904\n",
      "1500 3.5165297985076904\n",
      "1600 2.171919107437134\n",
      "1700 3.008462905883789\n",
      "1800 3.1921465396881104\n",
      "1900 2.858656644821167\n",
      "2000 4.319719314575195\n",
      "2100 2.9291839599609375\n",
      "2200 3.1579742431640625\n",
      "2300 4.106302738189697\n",
      "2400 3.9393527507781982\n",
      "2500 2.7026126384735107\n",
      "2600 2.8480727672576904\n",
      "2700 2.879875898361206\n",
      "2800 3.5509088039398193\n",
      "2900 2.88134765625\n",
      "3000 3.210909843444824\n",
      "3100 3.348668336868286\n",
      "3200 3.716068983078003\n",
      "3300 3.0529119968414307\n",
      "3400 3.756510019302368\n",
      "3500 2.569488525390625\n",
      "3600 3.415264129638672\n",
      "3700 3.6187942028045654\n",
      "3800 3.397826910018921\n",
      "3900 2.8175899982452393\n",
      "4000 2.659585952758789\n",
      "4100 3.6337482929229736\n",
      "4200 3.0312070846557617\n",
      "4300 3.014937162399292\n",
      "4400 3.188190221786499\n",
      "4500 2.780113935470581\n",
      "4600 3.44659161567688\n",
      "4700 2.986910820007324\n",
      "4800 2.737032890319824\n",
      "4900 2.862701177597046\n",
      "5000 2.793269395828247\n",
      "5100 3.609917640686035\n",
      "5200 3.5499284267425537\n",
      "5300 2.9595859050750732\n",
      "5400 2.749995470046997\n",
      "5500 3.2234370708465576\n",
      "5600 2.2037458419799805\n",
      "5700 2.584827423095703\n",
      "5800 2.3471667766571045\n",
      "5900 3.66544246673584\n",
      "6000 2.8086650371551514\n",
      "6100 4.0624871253967285\n",
      "6200 4.618109703063965\n",
      "6300 2.879136800765991\n",
      "6400 2.476234197616577\n",
      "6500 3.895352602005005\n",
      "6600 3.03903865814209\n",
      "6700 2.8363325595855713\n",
      "6800 3.987164258956909\n",
      "6900 3.617067337036133\n",
      "7000 2.8971974849700928\n",
      "7100 2.684724807739258\n",
      "7200 3.6022491455078125\n",
      "7300 3.6036739349365234\n",
      "7400 3.08895206451416\n",
      "7500 2.1398427486419678\n",
      "7600 3.98580002784729\n",
      "7700 2.6638481616973877\n",
      "7800 3.3451716899871826\n",
      "7900 2.165562391281128\n",
      "8000 3.0132272243499756\n",
      "8100 3.3268582820892334\n",
      "8200 2.300272226333618\n",
      "8300 3.053279161453247\n",
      "8400 3.0031001567840576\n",
      "8500 3.9225170612335205\n",
      "8600 3.5253992080688477\n",
      "8700 3.3492908477783203\n",
      "8800 3.1608235836029053\n",
      "8900 2.5666491985321045\n",
      "9000 2.9087870121002197\n",
      "9100 3.9788639545440674\n",
      "9200 4.071422100067139\n",
      "9300 2.993753671646118\n",
      "9400 3.4132239818573\n",
      "9500 3.0860111713409424\n",
      "9600 3.1035268306732178\n",
      "9700 2.1182680130004883\n",
      "9800 3.7002782821655273\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg11_bn(pretrained=True) \n",
    "model.classifier[6] = nn.Linear(4096,251)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=.9, nesterov=True)\n",
    "\n",
    "train(model, optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4462 / 11994 correct (37.20)\n",
      "done writing\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(val_loader, model)\n",
    "model.eval()\n",
    "model.to(device=device)\n",
    "with open('submission2.txt', 'w') as file:\n",
    "    file.write(\"label1 label2 label3\\n\")\n",
    "    with torch.no_grad():\n",
    "        for x, y, path in test_loader:\n",
    "            name = path[0][-15:]\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            scores = model(x)\n",
    "            out_labels = [int(x) for x in (torch.topk(scores, 3)[1][0])]\n",
    "            file.write(name + \",\" + str(out_labels[0]) + \" \" + str(out_labels[1]) + \" \" + str(out_labels[2]) + \"\\n\")\n",
    "print(\"done writing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7097613  0.59887534 0.54972327]\n",
      "[0.19917071 0.22445115 0.24484591]\n"
     ]
    }
   ],
   "source": [
    "# find the mean of the images \n",
    "images, labels = iter(test_loader).next()\n",
    "numpy_images = images.numpy()\n",
    "\n",
    "per_image_mean = np.mean(numpy_images, axis=(2,3)) #Shape (32,3)\n",
    "per_image_std = np.std(numpy_images, axis=(2,3)) #Shape (32,3)\n",
    "\n",
    "pop_channel_mean = np.mean(per_image_mean, axis=0) # Shape (3,)\n",
    "pop_channel_std = np.mean(per_image_std, axis=0)\n",
    "print(pop_channel_mean)\n",
    "print(pop_channel_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
